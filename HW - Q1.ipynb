{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exciting-strain",
   "metadata": {},
   "source": [
    "## 1 The cliff problem (3 pts.)\n",
    "\n",
    "Consider the following problem. An agent must navigate the grid world represented in Fig. 1, where the\n",
    "grey area corresponds to a cliff that the agent must avoid. The goal state corresponds to the cell marked\n",
    "with a G, while the cell marked with an S corresponds to a starting state. At every step, the agent receives\n",
    "a reward of −1 except in the cliff region, where the reward is −100. Whenever the agent steps into a cliff\n",
    "state, its position is reset back to the start state. When the agent steps into the goal state, the episode ends.\n",
    "The agent has available four actions: up (U), down (D), left (L) and right (R), all of which move the agent\n",
    "deterministically in the corresponding direction.\n",
    "\n",
    "![image.info](./pictures/grid-world.png)\n",
    "\n",
    "In this question, you will compare the performance of SARSA and Q-learning on the cliff task. To do\n",
    "so, assume that the agent follows an ε-greedy policy, with ε = 0.15. Run both algorithms for 500 episodes, making sure that the Q-values for both methods are initialized to 0. Consider throughout that γ = 1 and use a step-size of α = 0.5.\n",
    "\n",
    "\n",
    "### Question 1. Compare:\n",
    "• The total reward in each episode for Q-learning and SARSA, plotting the two in a single plot.<br>\n",
    "• The resulting policy after the 500 episodes.<br><br>\n",
    "Comment any differences observed.<br><br>\n",
    "<b>Note<b>: To mitigate the effect of noise on the plot, perform multiple runs and average the result across\n",
    "runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-meditation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T11:48:01.269760Z",
     "start_time": "2021-11-12T11:48:01.230260Z"
    }
   },
   "source": [
    "## Sarsa pseudo code\n",
    "\n",
    "![image.info](./pictures/sarsa.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "given-scheduling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T13:24:42.956990Z",
     "start_time": "2021-11-12T13:24:42.921087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "following-redhead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T15:46:44.349832Z",
     "start_time": "2021-11-12T15:46:44.135405Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-170-d598c7d118f0>:193: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for episode in tqdm.tnrange(self.episodes):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb608dff0e44c398429eda25ab8028b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sarsa Implementation\n",
    "\n",
    "class Cliff(object):\n",
    "    \n",
    "    def __init__(self, episodes=500, gamma=1.0, nrows=4, ncols=11, epsilon=0.15, alpha=0.5):\n",
    "        \n",
    "        if (ncols < 3) | (nrows < 2):\n",
    "            print('Input at least two rows and three columns')\n",
    "            return\n",
    "        \n",
    "        # Action space: A = {up, down, left, right}\n",
    "        # self.actions = [0, 1, 2, 3]\n",
    "        \n",
    "        # Space size\n",
    "        self.nrows = nrows\n",
    "        self.ncols = ncols\n",
    "\n",
    "        # Grid space - available states: S = {4*11 matrix}\n",
    "        self.states = np.zeros((nrows, ncols))\n",
    "        \n",
    "        # Current state, initial state (nrows-1, 0)\n",
    "        self.current_row = None\n",
    "        self.current_col = None\n",
    "        \n",
    "        # Goal state\n",
    "        self.goal_row = nrows-1\n",
    "        self.goal_col = ncols-1\n",
    "        \n",
    "        # Number of episodes\n",
    "        self.episodes = episodes\n",
    "        \n",
    "        # Q values\n",
    "        self.q_up = None\n",
    "        self.q_down = None\n",
    "        self.q_left = None\n",
    "        self.q_right = None\n",
    "        \n",
    "        # Rewards: -1 for every action, except for cliff, where it is -100\n",
    "        self.rewards = np.zeros((nrows, ncols)) - 1\n",
    "        self.rewards[nrows-1, 1:ncols-1] = -100 \n",
    "        # self.rewards[nrows-1, ncols-1] = 0\n",
    "\n",
    "        # Discount factor gamma\n",
    "        self.gamma = float(gamma)\n",
    "        \n",
    "        # Epsilon value for epsilon-greedy policy exploration\n",
    "        self.epsilon = float(epsilon)\n",
    "        \n",
    "        # Step size alpha for incremental value approximation\n",
    "        self.alpha = float(alpha)\n",
    "        \n",
    "        # Optimal policy\n",
    "        self.policy = None\n",
    "        \n",
    "        # Formated policy\n",
    "        self.fpolicy = None\n",
    "        \n",
    "        # Get the reward history\n",
    "        self.episode_rewards = []\n",
    "        self.accumulated_rewards = []\n",
    "        \n",
    "        # Timestep history\n",
    "        self.history = []\n",
    "        \n",
    "        #print(self.states)\n",
    "        #print(self.rewards)\n",
    "        #print(self.q_up)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def initialize_agent(self):\n",
    "        self.current_row = self.nrows-1\n",
    "        self.current_col = 0\n",
    "    \n",
    "    def initialize_q(self):\n",
    "        # Q-values: arbitrarily set, but for this homework will be set to 0\n",
    "        self.q_up = np.zeros((self.nrows, self.ncols))\n",
    "        self.q_up[self.nrows-1, self.ncols-1] = 0\n",
    "        \n",
    "        self.q_down = np.zeros((self.nrows, self.ncols))\n",
    "        self.q_down[self.nrows-1, self.ncols-1] = 0\n",
    "        \n",
    "        self.q_left = np.zeros((self.nrows, self.ncols))\n",
    "        self.q_left[self.nrows-1, self.ncols-1] = 0\n",
    "        \n",
    "        self.q_right = np.zeros((self.nrows, self.ncols))\n",
    "        self.q_right[self.nrows-1, self.ncols-1] = 0\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def epsilon_greedy(self, state_row, state_col):\n",
    "        next_action = None\n",
    "        if np.random.random() < self.epsilon:\n",
    "            next_action = np.random.randint(4)\n",
    "        else:\n",
    "            next_action = np.argmax([self.q_up[state_row, state_col],\n",
    "                                     self.q_down[state_row, state_col],\n",
    "                                     self.q_left[state_row, state_col],\n",
    "                                     self.q_right[state_row, state_col]])\n",
    "        return next_action\n",
    "    \n",
    "            \n",
    "    def go_up(self, state_row, state_col):\n",
    "        if self.current_row - 1 >= 0:\n",
    "            return self.current_row - 1, self.current_col\n",
    "        return self.current_row, self.current_col\n",
    "\n",
    "\n",
    "    def go_down(self, state_row, state_col):\n",
    "        if self.current_row + 1 < self.nrows:\n",
    "            return self.current_row + 1, self.current_col\n",
    "        return self.current_row, self.current_col\n",
    "\n",
    "\n",
    "    def go_left(self, state_row, state_col):\n",
    "        if self.current_col - 1 >= 0:\n",
    "            return self.current_row, self.current_col - 1\n",
    "        return self.current_row, self.current_col\n",
    "\n",
    "    def go_right(self, state_row, state_col):\n",
    "        if self.current_col + 1 < self.ncols:\n",
    "            return self.current_row, self.current_col + 1\n",
    "        return self.current_row, self.current_col\n",
    "\n",
    "\n",
    "    def do_action(self, action, state_row, state_col):\n",
    "        if action == 0:\n",
    "            return self.go_up(state_row, state_col)\n",
    "        elif action == 1:\n",
    "            return self.go_down(state_row, state_col)\n",
    "        elif action == 2:\n",
    "            return self.go_left(state_row, state_col)\n",
    "        elif action == 3:\n",
    "            return self.go_right(state_row, state_col)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def get_q(self, action, current_row, current_col):\n",
    "        if action == 0:\n",
    "            return self.q_up[current_row, current_col]\n",
    "        elif action == 1:\n",
    "            return self.q_down[current_row, current_col]\n",
    "        elif action == 2:\n",
    "            return self.q_left[current_row, current_col]\n",
    "        elif action == 3:\n",
    "            return self.q_right[current_row, current_col]\n",
    "        \n",
    "        \n",
    "    def set_q(self, action, current_row, current_col, value):\n",
    "        if action == 0:\n",
    "            self.q_up[current_row, current_col] = value\n",
    "        elif action == 1:\n",
    "            self.q_down[current_row, current_col] = value\n",
    "        elif action == 2:\n",
    "            self.q_left[current_row, current_col] = value\n",
    "        elif action == 3:\n",
    "            self.q_right[current_row, current_col] = value\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def get_policy(self):\n",
    "        max_q = np.zeros((self.nrows, self.ncols))\n",
    "        for row in np.arange(self.nrows):\n",
    "            for col in np.arange(self.ncols):\n",
    "                max_q[row, col] = np.argmax([self.q_up[row, col],\n",
    "                                             self.q_down[row, col],\n",
    "                                             self.q_left[row, col],\n",
    "                                             self.q_right[row, col]])\n",
    "        return max_q\n",
    "    \n",
    "    \n",
    "    def format_policy(self):\n",
    "        if self.policy is not None:\n",
    "        \n",
    "            # Get the unicode codes for arrows for a nicer representation\n",
    "            arrow_dictionary = {'0': 'U+21E1',\n",
    "                                '1': 'U+21E3',\n",
    "                                '2': 'U+21E0',\n",
    "                                '3': 'U+21E2'}\n",
    "\n",
    "            table_arrow = np.zeros((self.nrows, self.ncols))\n",
    "            \n",
    "        return\n",
    "            \n",
    "            \n",
    "    def sarsa_iteration(self):\n",
    "        \n",
    "        # Initialize the Q values\n",
    "        self.initialize_q()\n",
    "        \n",
    "        # Go through each episode:\n",
    "        for episode in tqdm.tnrange(self.episodes):\n",
    "            \n",
    "            # State initialization\n",
    "            self.initialize_agent()\n",
    "            \n",
    "            # Choose action with epsilon-greedy (initial action)\n",
    "            action = self.epsilon_greedy(self.current_row, self.current_col)\n",
    "            \n",
    "            episode_timestep = 0\n",
    "            episode_total_reward = 0\n",
    "            episode_rewards = []\n",
    "            \n",
    "            # For each step of the episode\n",
    "            while True:                  \n",
    "                #print(self.current_row, self.current_col)\n",
    "                #print(action)\n",
    "                    \n",
    "                # Get new state S\n",
    "                new_row, new_col = self.do_action(action, self.current_row, self.current_col)\n",
    "                \n",
    "                # Immediate reward R\n",
    "                new_reward = self.rewards[new_row, new_col]\n",
    "                \n",
    "                # Get new action\n",
    "                new_action = self.epsilon_greedy(new_row, new_col)\n",
    "                \n",
    "                # Current Q\n",
    "                current_q = self.get_q(action, self.current_row, self.current_col)\n",
    "                \n",
    "                # Q'\n",
    "                new_q = self.get_q(new_action, new_row, new_col)\n",
    "                #print('Q: {}'.format(new_q))\n",
    "                \n",
    "                # Update Q value\n",
    "                temp_q = current_q + self.alpha*(new_reward + self.gamma*new_q - current_q)\n",
    "                \n",
    "                # Set the new Q value for this action\n",
    "                self.set_q(action, self.current_row, self.current_col, temp_q)\n",
    "                \n",
    "                # Update action and state values\n",
    "                self.current_row, self.current_col = self.do_action(action, self.current_row, self.current_col)\n",
    "                action = new_action\n",
    "                \n",
    "                episode_timestep += 1\n",
    "                episode_total_reward += new_reward\n",
    "                episode_rewards.append(new_reward)\n",
    "                \n",
    "                if (self.current_row == self.goal_row) & (self.current_col == self.goal_col):\n",
    "                    break\n",
    "            \n",
    "            self.history.append(episode_timestep)\n",
    "            self.accumulated_rewards.append(episode_total_reward)\n",
    "            self.episode_rewards.append(episode_rewards)\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def do_iteration(self):\n",
    "        self.sarsa_iteration()\n",
    "        self.policy = self.get_policy()\n",
    "        \n",
    "    \n",
    "sarsacliff = Cliff(nrows=4, ncols=11, gamma=1.0, alpha=0.5)\n",
    "sarsacliff.do_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "stuffed-limitation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T15:47:11.509586Z",
     "start_time": "2021-11-12T15:47:11.400488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21e10edd670>]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sarsacliff.accumulated_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-johnston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
