{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "happy-petite",
   "metadata": {},
   "source": [
    "## 1 The cliff problem (3 pts.)\n",
    "\n",
    "Consider the following problem. An agent must navigate the grid world represented in Fig. 1, where the\n",
    "grey area corresponds to a cliff that the agent must avoid. The goal state corresponds to the cell marked\n",
    "with a G, while the cell marked with an S corresponds to a starting state. At every step, the agent receives\n",
    "a reward of −1 except in the cliff region, where the reward is −100. Whenever the agent steps into a cliff\n",
    "state, its position is reset back to the start state. When the agent steps into the goal state, the episode ends.\n",
    "The agent has available four actions: up (U), down (D), left (L) and right (R), all of which move the agent\n",
    "deterministically in the corresponding direction.\n",
    "\n",
    "![image.info](./pictures/grid-world.png)\n",
    "\n",
    "In this question, you will compare the performance of SARSA and Q-learning on the cliff task. To do\n",
    "so, assume that the agent follows an ε-greedy policy, with ε = 0.15. Run both algorithms for 500 episodes, making sure that the Q-values for both methods are initialized to 0. Consider throughout that γ = 1 and use a step-size of α = 0.5.\n",
    "\n",
    "\n",
    "### Question 1. Compare:\n",
    "• The total reward in each episode for Q-learning and SARSA, plotting the two in a single plot.<br>\n",
    "• The resulting policy after the 500 episodes.<br><br>\n",
    "Comment any differences observed.<br><br>\n",
    "<b>Note<b>: To mitigate the effect of noise on the plot, perform multiple runs and average the result across\n",
    "runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-given",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T11:48:01.269760Z",
     "start_time": "2021-11-12T11:48:01.230260Z"
    }
   },
   "source": [
    "## Sarsa pseudo code\n",
    "\n",
    "![image.info](./pictures/sarsa.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "independent-string",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T12:01:46.724059Z",
     "start_time": "2021-11-12T12:01:46.709100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [  -1. -100. -100. -100. -100. -100. -100. -100. -100. -100.   -1.]]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SARSACliff at 0x21e7de5c850>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sarsa Implementation\n",
    "\n",
    "class SARSACliff(object):\n",
    "    \n",
    "    def __init__(self, gamma=1):\n",
    "        \n",
    "        # Action space: A = {up, down, left, right}\n",
    "        self.actions = [0, 1, 2, 3]\n",
    "\n",
    "        # Grid space - available states: S = {4*11 matrix}\n",
    "        self.states = np.zeros((4, 11))\n",
    "        \n",
    "        # Q-values: arbitrarily set to 1, except for terminal state, where it will be zero\n",
    "        self.q_up = np.zeros((4, 11)) + 1\n",
    "        self.q_up[3, 10] = 0\n",
    "        \n",
    "        self.q_down = np.zeros((4, 11)) + 1\n",
    "        self.q_down[3, 10] = 0\n",
    "        \n",
    "        self.q_left = np.zeros((4, 11)) + 1\n",
    "        self.q_left[3, 10] = 0\n",
    "        \n",
    "        self.q_right = np.zeros((4, 11)) + 1\n",
    "        self.q_right[3, 10] = 0\n",
    "        \n",
    "        # Rewards: -1 for every action, except for cliff, where it is -100\n",
    "        self.rewards = np.zeros((4, 11)) - 1\n",
    "        self.rewards[3, 1:10] = -100 \n",
    "\n",
    "        # Discount factor gamma\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        print(self.states)\n",
    "        print(self.rewards)\n",
    "        print(self.q_up)\n",
    "        \n",
    "        return\n",
    "    \n",
    "SARSACliff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-signal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
